{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0534ed0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenerativeai\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgenai\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_google_genai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GoogleGenerativeAI\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JSONLoader\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "from langchain.document_loaders import JSONLoader\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "#print(os.getenv(\"GOOGLE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a89d6bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to access folder: 'D:\\my_code_profile\\group_project\\Rag_Base\\shopping'\n",
      "Folder 'D:\\my_code_profile\\group_project\\Rag_Base\\shopping' exists. Listing contents...\n",
      "Loaded 3 pages\n"
     ]
    }
   ],
   "source": [
    "#print(openai_api_key)\n",
    "\n",
    "folder = r\"D:\\my_code_profile\\group_project\\Rag_Base\\shopping\"\n",
    "documents = []\n",
    "\n",
    "print(f\"Attempting to access folder: '{folder}'\") # Add this line\n",
    "if not os.path.exists(folder): # Add this check\n",
    "    print(f\"Error: Folder '{folder}' does not exist.\")\n",
    "else:\n",
    "    print(f\"Folder '{folder}' exists. Listing contents...\")\n",
    "\n",
    "for file in os.listdir(folder):\n",
    "    if file.endswith(\".json\"):\n",
    "        f = os.path.join(folder, file)\n",
    "        loader= JSONLoader(file_path=f, jq_schema = \".\", text_content=False )  \n",
    "        documents.extend(loader.load())\n",
    "\n",
    "print(f\"Loaded {len(documents)} pages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cf4b98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS Document Index Loaded from existing directory.\n"
     ]
    }
   ],
   "source": [
    "faiss_index_dir = \"faiss_index\"  # You can change this path as needed\n",
    "\n",
    "embedding_model = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "if not os.path.exists(faiss_index_dir):\n",
    "    os.makedirs(faiss_index_dir)\n",
    "    print(f\"Created FAISS index directory: {faiss_index_dir}\")\n",
    "\n",
    "faiss_main_file = os.path.join(faiss_index_dir, \"index.faiss\")\n",
    "faiss_pkl_file = os.path.join(faiss_index_dir, \"index.pkl\")\n",
    "\n",
    "if os.path.exists(faiss_main_file) and os.path.exists(faiss_pkl_file):\n",
    "    # If index exists, load it\n",
    "    vectorstore = FAISS.load_local(faiss_index_dir, embedding_model, allow_dangerous_deserialization=True)\n",
    "    print(\"FAISS Document Index Loaded from existing directory.\")\n",
    "else:\n",
    "    # If index does not exist, create it and save it\n",
    "    print(\"Creating and saving FAISS Document Index...\")\n",
    "    vectorstore = FAISS.from_documents(documents, embedding_model)\n",
    "    vectorstore.save_local(faiss_index_dir)\n",
    "    print(\"FAISS Document Index Created and Saved.\")\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd024826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS Document Index Loaded from existing directory.\n"
     ]
    }
   ],
   "source": [
    "faiss_main_file = os.path.join(faiss_index_dir, \"index.faiss\")\n",
    "faiss_pkl_file = os.path.join(faiss_index_dir, \"index.pkl\")\n",
    "\n",
    "if os.path.exists(faiss_main_file) and os.path.exists(faiss_pkl_file):\n",
    "    # If index exists, load it\n",
    "    vectorstore = FAISS.load_local(faiss_index_dir, embedding_model, allow_dangerous_deserialization=True)\n",
    "    print(\"FAISS Document Index Loaded from existing directory.\")\n",
    "else:\n",
    "    # If index does not exist, create it and save it\n",
    "    print(\"Creating and saving FAISS Document Index...\")\n",
    "    vectorstore = FAISS.from_documents(documents, embedding_model)\n",
    "    vectorstore.save_local(faiss_index_dir)\n",
    "    print(\"FAISS Document Index Created and Saved.\")\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a728ba56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_15584\\1853987188.py:25: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "template = '''\n",
    "Chat History : {chat_history}\n",
    "Context : {context}\n",
    "Question : {question}\n",
    "Instructions:\n",
    "1. For the cloth tracker you have to use the below context:\n",
    "-> Apply the appropriate formula to calculate the CO₂ amount based on the question\n",
    "use this formula: Total = [quantity x average weight] x emission factor,  where user will give quantity and material type. from that get average weight from context.\n",
    "-> Output the CO₂ amount (in kg).\n",
    "-> Also give 2 suggestions to reduce this emission.\n",
    "\n",
    "2 For the Grocery tracker you have to use the below context:\n",
    "-> Apply the appropriate formula to calculate the CO₂ amount based on the question\n",
    "use these formulas:\n",
    "for items with emission factor in kg: Total = quantity x emission factor\n",
    "for items with emission factor in liter: Total = quantity x emission factor in liter x 0.001\n",
    "-> Output the CO₂ amount (in kg).\n",
    "-> Also give 2 suggestions to reduce this emission.\n",
    "\n",
    "\n",
    "'''\n",
    "custom_prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# --- Memory ---\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "824d8481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS Document Index Loaded from existing directory.\n"
     ]
    }
   ],
   "source": [
    "faiss_main_file = os.path.join(faiss_index_dir, \"index.faiss\")\n",
    "faiss_pkl_file = os.path.join(faiss_index_dir, \"index.pkl\")\n",
    "\n",
    "if os.path.exists(faiss_main_file) and os.path.exists(faiss_pkl_file):\n",
    "    # If index exists, load it\n",
    "    vectorstore = FAISS.load_local(faiss_index_dir, embedding_model, allow_dangerous_deserialization=True)\n",
    "    print(\"FAISS Document Index Loaded from existing directory.\")\n",
    "else:\n",
    "    # If index does not exist, create it and save it\n",
    "    print(\"Creating and saving FAISS Document Index...\")\n",
    "    vectorstore = FAISS.from_documents(documents, embedding_model)\n",
    "    vectorstore.save_local(faiss_index_dir)\n",
    "    print(\"FAISS Document Index Created and Saved.\")\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38bd5af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.7)\n",
    "\n",
    "conversational_qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever = retriever,\n",
    "    memory=memory,\n",
    "    combine_docs_chain_kwargs={\"prompt\": custom_prompt},\n",
    "    return_source_documents=False \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ad8faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIzaSyDXs0FVgsdOAVLTKbsQGsPclv_Dq_Ml1V0\n",
      "\n",
      "--- RAG Chatbot (with Conversation History) ---\n",
      "Type 'exit', 'quit', or 'bye' to end the conversation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_15584\\1290756437.py:13: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = conversational_qa_chain({\"question\": user_query})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: You consumed 3.5 kg of CO₂ emissions for your groceries.\n",
      "\n",
      "Here are 2 suggestions to reduce your emissions:\n",
      "1.  Consider plant-based milk alternatives (like oat or almond milk) which generally have lower emissions than dairy milk.\n",
      "2.  Reduce your overall consumption of added sugars, as their production contributes to emissions.\n",
      "Bot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "#print(os.getenv(\"GOOGLE_API_KEY\"))\n",
    "print(\"\\n--- RAG Chatbot (with Conversation History) ---\")\n",
    "print(\"Type 'exit', 'quit', or 'bye' to end the conversation.\")\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_query = input(\"You: \")\n",
    "        if user_query.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
    "            print(\"Bot: Goodbye!\")\n",
    "            break\n",
    "\n",
    " \n",
    "        response = conversational_qa_chain({\"question\": user_query})\n",
    "        print(f\"Bot: {response['answer']}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
