{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e16bc3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "from langchain.document_loaders import JSONLoader\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY_4\")\n",
    "#print(os.getenv(\"GOOGLE_API_KEY_4\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "049ed238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to access folder: 'D:\\my_code_profile\\group_project\\Verdant\\Verdant\\Rag_Base\\jsonfiles\\energy'\n",
      "Folder 'D:\\my_code_profile\\group_project\\Verdant\\Verdant\\Rag_Base\\jsonfiles\\energy' exists. Listing contents...\n",
      "Loaded 1 pages\n"
     ]
    }
   ],
   "source": [
    "#print(openai_api_key)\n",
    "\n",
    "folder = r\"D:\\my_code_profile\\group_project\\Verdant\\Verdant\\Rag_Base\\jsonfiles\\energy\"\n",
    "documents = []\n",
    "\n",
    "print(f\"Attempting to access folder: '{folder}'\") # Add this line\n",
    "if not os.path.exists(folder): # Add this check\n",
    "    print(f\"Error: Folder '{folder}' does not exist.\")\n",
    "else:\n",
    "    print(f\"Folder '{folder}' exists. Listing contents...\")\n",
    "\n",
    "for file in os.listdir(folder):\n",
    "    if file.endswith(\".json\"):\n",
    "        f = os.path.join(folder, file)\n",
    "        loader= JSONLoader(file_path=f, jq_schema = \".\", text_content=False )  \n",
    "        documents.extend(loader.load())\n",
    "\n",
    "print(f\"Loaded {len(documents)} pages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ceb8b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created FAISS index directory: faiss_index_energy\n",
      "Creating and saving FAISS Document Index...\n",
      "FAISS Document Index Created and Saved.\n"
     ]
    }
   ],
   "source": [
    "faiss_index_dir = \"faiss_index_energy\"  # You can change this path as needed\n",
    "\n",
    "embedding_model = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=google_api_key)\n",
    "if not os.path.exists(faiss_index_dir):\n",
    "    os.makedirs(faiss_index_dir)\n",
    "    print(f\"Created FAISS index directory: {faiss_index_dir}\")\n",
    "\n",
    "faiss_main_file = os.path.join(faiss_index_dir, \"index.faiss\")\n",
    "faiss_pkl_file = os.path.join(faiss_index_dir, \"index.pkl\")\n",
    "\n",
    "if os.path.exists(faiss_main_file) and os.path.exists(faiss_pkl_file):\n",
    "    # If index exists, load it\n",
    "    vectorstore = FAISS.load_local(faiss_index_dir, embedding_model, allow_dangerous_deserialization=True)\n",
    "    print(\"FAISS Document Index Loaded from existing directory.\")\n",
    "else:\n",
    "    # If index does not exist, create it and save it\n",
    "    print(\"Creating and saving FAISS Document Index...\")\n",
    "    vectorstore = FAISS.from_documents(documents, embedding_model)\n",
    "    vectorstore.save_local(faiss_index_dir)\n",
    "    print(\"FAISS Document Index Created and Saved.\")\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6068fb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "template = '''\n",
    "Chat History : {chat_history}\n",
    "Context : {context}\n",
    "Question : {question}\n",
    "Instructions:\n",
    "1. For the Energy tracker you have to use the below context:\n",
    "-> Apply the appropriate formula to calculate the CO₂ amount based on the question\n",
    "use this formula: Total = quantity * emission factor,  where user will give quantity and material type. from that get average weight from context.\n",
    "In the json file all the energy with there unit and there emission factor is given use that .\n",
    "In the quantity the user will give input as number and then multiply it to emission factor of that energy\n",
    "-> Output the CO₂ amount (in kg).\n",
    "-> Also give 2 suggestions to reduce this emission.\n",
    "\n",
    "'''\n",
    "custom_prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# --- Memory ---\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a593a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.7, google_api_key=google_api_key)\n",
    "\n",
    "conversational_qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever = retriever,\n",
    "    memory=memory,\n",
    "    combine_docs_chain_kwargs={\"prompt\": custom_prompt},\n",
    "    return_source_documents=False \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b86a2f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- RAG Chatbot (with Conversation History) ---\n",
      "Type 'exit', 'quit', or 'bye' to end the conversation.\n",
      "Bot: You can calculate the **total CO2 emissions (in kg)** for various energy sources.\n",
      "\n",
      "The inputs required are:\n",
      "1.  The **quantity** (a number) of the energy source consumed.\n",
      "2.  The **type of energy source** (e.g., electricity, LPG, PNG, petrol, diesel, CNG, firewood, charcoal, or cow dung).\n",
      "Bot: For 10 liters of petrol, the CO2 emissions would be:\n",
      "\n",
      "*   **Petrol Emission Factor:** 2.31 kg CO2e per liter\n",
      "*   **Quantity:** 10 liters\n",
      "\n",
      "**Calculation:** 10 liters * 2.31 kg CO2e/liter = **23.1 kg CO2e**\n",
      "\n",
      "**Suggestions to reduce this emission:**\n",
      "1.  **Opt for public transportation, carpooling, cycling, or walking** for your commute and errands whenever possible.\n",
      "2.  **Maintain your vehicle regularly** to ensure optimal fuel efficiency, and consider switching to more fuel-efficient or electric vehicles in the future.\n",
      "Bot: For 10 liters of petrol, the CO2 emissions would be:\n",
      "\n",
      "*   **Petrol Emission Factor:** 2.31 kg CO2e per liter\n",
      "*   **Quantity:** 10 liters\n",
      "\n",
      "**Calculation:** 10 liters * 2.31 kg CO2e/liter = **23.1 kg CO2e**\n",
      "\n",
      "**Suggestions to reduce this emission:**\n",
      "1.  **Opt for public transportation, carpooling, cycling, or walking** for your commute and errands whenever possible.\n",
      "2.  **Maintain your vehicle regularly** to ensure optimal fuel efficiency, and consider switching to more fuel-efficient or electric vehicles in the future.\n",
      "Bot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "#print(os.getenv(\"GOOGLE_API_KEY\"))\n",
    "print(\"\\n--- RAG Chatbot (with Conversation History) ---\")\n",
    "print(\"Type 'exit', 'quit', or 'bye' to end the conversation.\")\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_query = input(\"You: \")\n",
    "        if user_query.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
    "            print(\"Bot: Goodbye!\")\n",
    "            break\n",
    "\n",
    " \n",
    "        response = conversational_qa_chain({\"question\": user_query})\n",
    "        print(f\"Bot: {response['answer']}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
